{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T01:30:12.365156Z",
     "start_time": "2021-12-14T01:30:08.064143Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import emot\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T01:30:12.572286Z",
     "start_time": "2021-12-14T01:30:12.369641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>music_app</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is by far the best music app I have ever ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I really like this app but I have tried an tri...</td>\n",
       "      <td>4</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This app is great, i've been using it for a co...</td>\n",
       "      <td>4</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not a bad music app. Selection is good could b...</td>\n",
       "      <td>3</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is one of the most used app on my phone, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating music_app\n",
       "0  This is by far the best music app I have ever ...       5    Amazon\n",
       "1  I really like this app but I have tried an tri...       4    Amazon\n",
       "2  This app is great, i've been using it for a co...       4    Amazon\n",
       "3  Not a bad music app. Selection is good could b...       3    Amazon\n",
       "4  This is one of the most used app on my phone, ...       2    Amazon"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"master_data.csv\").drop(\"Unnamed: 0\", axis = 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T00:05:23.976775Z",
     "start_time": "2021-12-14T00:05:23.565833Z"
    }
   },
   "source": [
    "### Approaches\n",
    "\n",
    "We want to be able to see which classification works the best.\n",
    "- We will first do the traditional approach with bag of words models, notably CountVectorize and TF-IDF vectorization\n",
    "- Next, we will do a spacy approach\n",
    "\n",
    "- The goal will be to beat the Bert model, which has a testing set accuracy of _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T01:30:12.592074Z",
     "start_time": "2021-12-14T01:30:12.577802Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I really like this app but I have tried an tried to find out why every time I get a phone call or I go out of my app when I push pause on my music an go back within minutes it goes an refreshes the whole app. I‚Äôm literally in the middle of a song so what is the purpose of refreshing the app üßêI tried to just start putting the music on an old phone I have that‚Äôs just for WiFi but even that if I‚Äôm closer to it an pause it, you can‚Äôt leave the app longer then a minute it seems without it just thinking your not coming back or something. An the other issue is it constantly takes random music that i do listen to often out of my music list. I‚Äôll add a song to my music an sometimes a playlist too, an I‚Äôll be listening to the song randomly later on a station that I choose an I‚Äôll go an decide to add it to a playlist an see that it‚Äôs not even in my music. So I‚Äôll add it again. I‚Äôve only notice it since like I said I‚Äôll decide to add it to a playlist an see it has the plus next to add music. But why is it constantly coming out of my music. I have checked an seen that most songs still be in a playlist but not added to my music.. again not understanding these little things. But Please please fix. The little things add up to annoyance when it‚Äôs continuously acting up..\n",
      "I really like this app but I have tried an tried to find out why every time I get a phone call or I go out of my app when I push pause on my music an go back within minutes it goes an refreshes the whole app. I‚Äôm literally in the middle of a song so what is the purpose of refreshing the app I tried to just start putting the music on an old phone I have that‚Äôs just for WiFi but even that if I‚Äôm closer to it an pause it, you can‚Äôt leave the app longer then a minute it seems without it just thinking your not coming back or something. An the other issue is it constantly takes random music that i do listen to often out of my music list. I‚Äôll add a song to my music an sometimes a playlist too, an I‚Äôll be listening to the song randomly later on a station that I choose an I‚Äôll go an decide to add it to a playlist an see that it‚Äôs not even in my music. So I‚Äôll add it again. I‚Äôve only notice it since like I said I‚Äôll decide to add it to a playlist an see it has the plus next to add music. But why is it constantly coming out of my music. I have checked an seen that most songs still be in a playlist but not added to my music.. again not understanding these little things. But Please please fix. The little things add up to annoyance when it‚Äôs continuously acting up..\n"
     ]
    }
   ],
   "source": [
    "x = data.loc[1][\"review\"]\n",
    "\n",
    "# code taken from https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b to remove emojis\n",
    "# this doesn't have the most up to date emojis so we had to find an updated version for some unicode\n",
    "\n",
    "def remove_emojis(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  \n",
    "                               u\"\\u3030\"\n",
    "                               \n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "print(x)\n",
    "print(remove_emojis(x))\n",
    "\n",
    "# henry package to emoji -> word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T01:30:12.615203Z",
     "start_time": "2021-12-14T01:30:12.595659Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!',\n",
       " ',',\n",
       " '.',\n",
       " ':',\n",
       " '?',\n",
       " 'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'music',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stopwords \n",
    "# we know the reviews are about music, so we remove the stopword music\n",
    "# we also remove punctuation\n",
    "# overall, the revies are clean, although there are emojis present. \n",
    "# for now we will keep emojis as they could be an indication in our classification\n",
    "\n",
    "stopword_list = set(stopwords.words('english') + [\"music\", \".\", \"!\", \"?\", \",\",\":\"])\n",
    "stopword_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T01:32:11.524800Z",
     "start_time": "2021-12-14T01:31:17.341014Z"
    }
   },
   "outputs": [],
   "source": [
    "#stemming, create an empty list, loop through and stem\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "reviews = data[\"review\"].str.lower()\n",
    "\n",
    "stemmed_list = []\n",
    "for i in reviews:\n",
    "    tokens = nltk.word_tokenize(i)\n",
    "    x = ''\n",
    "    for j in tokens:\n",
    "        x = x + ' ' + stemmer.stem(word = j)\n",
    "    stemmed_list.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T01:33:12.896210Z",
     "start_time": "2021-12-14T01:33:12.889889Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' i hate mani thing about thi app , but the featur most bothersom to me of late is the keep listen featur . the sleep timer is turn off , but everi hour i get ask am i still listen to music . did i stop the music ? ! i have my devic plug in across the room becaus it ‚Äô s not compat with legrand digit audio ( fix thi too ! ) . so , everi hour when the music stop i have to go press keep listen . i ‚Äô m not oppos to exercis , but i ‚Äô m tri to work , and thi incess disrupt make me want to pay for a differ stream music servic . thi should onli happen if i engag the sleep timer . thi is a useless featur , especi if i am actual stream on wifi and have the stream onli on wifi featur engag or am in offlin mode listen to download music . get rid of thi . anoth huge annoy is the amount of data thi app use even in data saver mode . my daili commut ( 160 minut total stream time ) use 1 gb of data ! mayb it would use less data if the lyric featur could be disabl . final your app support wa useless for provid feedback , so hope someon is read these review .',\n",
       " ' i just want to say that i love love love music . i listen to music liter ever day . but there is one thing that realli get on my nerv . the music unlimit thing is a good idea but , some song that i realli like to listen to are music unlimit , and i love to listen to taylor swift but , a few day ago when i tri to play it , it said that it wa music unlimit . but mayb you could have like ‚Äú pay 10 $ for one week of music unlimit song ‚Äù or ‚Äú pay 20 $ for a year ‚Äù or someth like that . you don ‚Äô t have to that but it ‚Äô s just a suggest . üòä updat : as i said befor i love music and i like the music unlimit idea but it ‚Äô s just kind of expens and when i tri to listen to certain song sometim the day after i listen to them they becom music unlimit when we don ‚Äô t pay for it in the first place . so i wa think that the person want to listen to music but can ‚Äô t becaus it is unlimit could pay , say , $ 20- $ 30 for a whole year or 1/2 a year of unlimit song . i ‚Äô m not tri to cut how much money you get i ‚Äô m just throw out some idea that you could possibl look at and talk it over . i hope that these idea come to be use in the futur .']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_list[5:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T01:38:09.824347Z",
     "start_time": "2021-12-14T01:38:09.806108Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thi is by far the best music app i have ever ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i realli like thi app but i have tri an tri t...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thi app is great , i 've been use it for a co...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not a bad music app . select is good could be...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thi is one of the most use app on my phone , ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72046</th>\n",
       "      <td>ùê†ùê®ùêöùê≠</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72047</th>\n",
       "      <td>i hate onli ad xd</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72048</th>\n",
       "      <td>i ca n't search and play some song other than...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72049</th>\n",
       "      <td>just work well</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72050</th>\n",
       "      <td>awesom</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72051 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 reviews  ratings\n",
       "0       thi is by far the best music app i have ever ...        5\n",
       "1       i realli like thi app but i have tri an tri t...        4\n",
       "2       thi app is great , i 've been use it for a co...        4\n",
       "3       not a bad music app . select is good could be...        3\n",
       "4       thi is one of the most use app on my phone , ...        2\n",
       "...                                                  ...      ...\n",
       "72046                                               ùê†ùê®ùêöùê≠        5\n",
       "72047                                  i hate onli ad xd        5\n",
       "72048   i ca n't search and play some song other than...        1\n",
       "72049                                     just work well        5\n",
       "72050                                             awesom        5\n",
       "\n",
       "[72051 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_df = pd.DataFrame(stemmed_list, columns = [\"reviews\"])\n",
    "stemmed_df[\"ratings\"] = data[\"rating\"]\n",
    "stemmed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T02:14:26.190388Z",
     "start_time": "2021-12-14T02:14:26.134739Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30871                  love to hear regga and r & b here .\n",
       "27029                                       solid interfac\n",
       "17779     i ‚Äô ve been use premium for year and i love i...\n",
       "42078     amaz real thi is realli amaz music i have but...\n",
       "67074     man thi app is goat . i like it a lot befor ,...\n",
       "                               ...                        \n",
       "37332     veri good and clear app . recent updat of dol...\n",
       "25631     doe it requir amazon prime to play song ? i '...\n",
       "42297     ca n't sign in to facebook with pearl pearl o...\n",
       "34959                  as soon as i search a song boom ! !\n",
       "64753                                                  üëçüëçüëç\n",
       "Name: reviews, Length: 57640, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_df_reviews = stemmed_df[\"reviews\"]\n",
    "stemmed_df_ratings = stemmed_df[\"ratings\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(stemmed_df_reviews, stemmed_df_ratings,\n",
    "                                                    test_size = 0.2, random_state = 17)\n",
    "# we now have training and testing data\n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T02:16:11.028572Z",
     "start_time": "2021-12-14T02:16:02.006208Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6637 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4183 accurate.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<57640x2000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 891652 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for our vectorization, we start with CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range = (1,2),\n",
    "                            stop_words = stopword_list,\n",
    "                            token_pattern = '(?u)\\\\b[a-zA-Z][a-zA-Z]+\\\\b', # removes emojis btw\n",
    "                            max_features = 2000,\n",
    "                            min_df = 2,\n",
    "                            binary = True)\n",
    "\n",
    "train_X = vectorizer.fit_transform(X_train)\n",
    "lr1 = LogisticRegression(multi_class='multinomial')\n",
    "lr1.fit(train_X, y_train)\n",
    "y_train_pred = lr1.predict(train_X)\n",
    "\n",
    "print(f'Without dimensionality reduction, on the training set, our model is {round(np.mean(y_train_pred == y_train),4)} accurate.')\n",
    "\n",
    "y_test_pred = lr1.predict(vectorizer.fit_transform(X_test))\n",
    "print(f'Without dimensionality reduction, on the testing set, our model is {round(np.mean(y_test_pred == y_test),4)} accurate.')\n",
    "\n",
    "# this is really not good, we are overfitting and our accuracy is really low. \n",
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T02:16:16.767470Z",
     "start_time": "2021-12-14T02:16:16.376312Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T01:55:03.848926Z",
     "start_time": "2021-12-14T01:54:58.634437Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6579 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4761 accurate.\n"
     ]
    }
   ],
   "source": [
    "# what if we use tfidf?\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range = (1,2),\n",
    "                            stop_words = stopword_list,\n",
    "                            token_pattern = '(?u)\\\\b[a-zA-Z][a-zA-Z]+\\\\b', # this will remove emojis btw\n",
    "                            max_features = 2000,\n",
    "                            min_df = 2,\n",
    "                            binary = True)\n",
    "\n",
    "train_X = vectorizer.fit_transform(X_train)\n",
    "lr1 = LogisticRegression(multi_class='multinomial')\n",
    "lr1.fit(train_X, y_train)\n",
    "y_train_pred = lr1.predict(train_X)\n",
    "\n",
    "print(f'Without dimensionality reduction, on the training set, our model is {round(np.mean(y_train_pred == y_train),4)} accurate.')\n",
    "\n",
    "y_test_pred = lr1.predict(vectorizer.fit_transform(X_test))\n",
    "print(f'Without dimensionality reduction, on the testing set, our model is {round(np.mean(y_test_pred == y_test),4)} accurate.')\n",
    "\n",
    "# this is really not good, we are overfitting and our accuracy is really low. \n",
    "# this model does better and improves our testing accuracy by over 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T02:04:28.857477Z",
     "start_time": "2021-12-14T02:02:05.202763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngrams = (1, 1); max_features = 500; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6518 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.3921 accurate.\n",
      "ngrams = (1, 1); max_features = 500; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6518 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.3921 accurate.\n",
      "ngrams = (1, 1); max_features = 500; min_df = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6518 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.3921 accurate.\n",
      "ngrams = (1, 1); max_features = 1000; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6518 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.3921 accurate.\n",
      "ngrams = (1, 1); max_features = 1000; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6518 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.3921 accurate.\n",
      "ngrams = (1, 1); max_features = 1000; min_df = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6518 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.3921 accurate.\n",
      "ngrams = (1, 1); max_features = 1500; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6518 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.3921 accurate.\n",
      "ngrams = (1, 1); max_features = 1500; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6518 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.3921 accurate.\n",
      "ngrams = (1, 1); max_features = 1500; min_df = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6518 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.3921 accurate.\n",
      "ngrams = (1, 1); max_features = 2000; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6518 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.3921 accurate.\n",
      "ngrams = (1, 1); max_features = 2000; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6518 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.3921 accurate.\n",
      "ngrams = (1, 1); max_features = 2000; min_df = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6518 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.3921 accurate.\n",
      "ngrams = (1, 1); max_features = 2500; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6518 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.3921 accurate.\n",
      "ngrams = (1, 1); max_features = 2500; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6518 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.3921 accurate.\n",
      "ngrams = (1, 1); max_features = 2500; min_df = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6518 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.3921 accurate.\n",
      "ngrams = (2, 2); max_features = 500; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6089 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.434 accurate.\n",
      "ngrams = (2, 2); max_features = 500; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6089 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.434 accurate.\n",
      "ngrams = (2, 2); max_features = 500; min_df = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6089 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.434 accurate.\n",
      "ngrams = (2, 2); max_features = 1000; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6089 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.434 accurate.\n",
      "ngrams = (2, 2); max_features = 1000; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6089 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.434 accurate.\n",
      "ngrams = (2, 2); max_features = 1000; min_df = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6089 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.434 accurate.\n",
      "ngrams = (2, 2); max_features = 1500; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6089 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.434 accurate.\n",
      "ngrams = (2, 2); max_features = 1500; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6089 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.434 accurate.\n",
      "ngrams = (2, 2); max_features = 1500; min_df = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6089 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.434 accurate.\n",
      "ngrams = (2, 2); max_features = 2000; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6089 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.434 accurate.\n",
      "ngrams = (2, 2); max_features = 2000; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6089 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.434 accurate.\n",
      "ngrams = (2, 2); max_features = 2000; min_df = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6089 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.434 accurate.\n",
      "ngrams = (2, 2); max_features = 2500; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6089 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.434 accurate.\n",
      "ngrams = (2, 2); max_features = 2500; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6089 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.434 accurate.\n",
      "ngrams = (2, 2); max_features = 2500; min_df = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6089 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.434 accurate.\n"
     ]
    }
   ],
   "source": [
    "# lets loop and find our best model\n",
    "ngrams = [(1,1), (2,2), (3,3)]\n",
    "max_features = [500,1000,1500,2000,2500]\n",
    "min_df = [2, 3, 5]\n",
    "\n",
    "for i in ngrams:\n",
    "    for j in max_features:\n",
    "        for k in min_df:=\n",
    "                print(f'ngrams = {i}; max_features = {j}; min_df = {k}')\n",
    "                vectorizer = TfidfVectorizer(ngram_range = i,\n",
    "                                            stop_words = stopword_list,\n",
    "                                            token_pattern = '(?u)\\\\b[a-zA-Z][a-zA-Z]+\\\\b', # this will remove emojis btw\n",
    "                                            max_features = j,\n",
    "                                            min_df = k,\n",
    "                                            binary = True)\n",
    "\n",
    "                train_X = vectorizer.fit_transform(X_train)\n",
    "                lr1 = LogisticRegression(multi_class='multinomial')\n",
    "                lr1.fit(train_X, y_train)\n",
    "                y_train_pred = lr1.predict(train_X)\n",
    "\n",
    "                print(f'Without dimensionality reduction, on the training set, our model is {round(np.mean(y_train_pred == y_train),4)} accurate.')\n",
    "\n",
    "                y_test_pred = lr1.predict(vectorizer.fit_transform(X_test))\n",
    "                print(f'Without dimensionality reduction, on the testing set, our model is {round(np.mean(y_test_pred == y_test),4)} accurate.')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
