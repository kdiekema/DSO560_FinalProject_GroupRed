{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:04:03.588391Z",
     "start_time": "2021-12-14T13:04:00.316110Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import emot\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:04:03.850992Z",
     "start_time": "2021-12-14T13:04:03.592302Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>music_app</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is by far the best music app I have ever ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I really like this app but I have tried an tri...</td>\n",
       "      <td>4</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This app is great, i've been using it for a co...</td>\n",
       "      <td>4</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not a bad music app. Selection is good could b...</td>\n",
       "      <td>3</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is one of the most used app on my phone, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating music_app\n",
       "0  This is by far the best music app I have ever ...       5    Amazon\n",
       "1  I really like this app but I have tried an tri...       4    Amazon\n",
       "2  This app is great, i've been using it for a co...       4    Amazon\n",
       "3  Not a bad music app. Selection is good could b...       3    Amazon\n",
       "4  This is one of the most used app on my phone, ...       2    Amazon"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"master_data.csv\").drop(\"Unnamed: 0\", axis = 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T00:05:23.976775Z",
     "start_time": "2021-12-14T00:05:23.565833Z"
    }
   },
   "source": [
    "### Approaches\n",
    "\n",
    "We want to be able to see which classification works the best.\n",
    "- We will first do the traditional approach with bag of words models, notably CountVectorize and TF-IDF vectorization\n",
    "- Next, we will use spacy \n",
    "\n",
    "- The goal will be to beat the Bert model (Operation Beat BERT), which has a testing accuracy of 61%, and \"1-off\" accuracy of 85%. This means that our Bert model classifies 85% of reviews within 1 star of their actual score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:04:03.868356Z",
     "start_time": "2021-12-14T13:04:03.858009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I really like this app but I have tried an tried to find out why every time I get a phone call or I go out of my app when I push pause on my music an go back within minutes it goes an refreshes the whole app. I‚Äôm literally in the middle of a song so what is the purpose of refreshing the app üßêI tried to just start putting the music on an old phone I have that‚Äôs just for WiFi but even that if I‚Äôm closer to it an pause it, you can‚Äôt leave the app longer then a minute it seems without it just thinking your not coming back or something. An the other issue is it constantly takes random music that i do listen to often out of my music list. I‚Äôll add a song to my music an sometimes a playlist too, an I‚Äôll be listening to the song randomly later on a station that I choose an I‚Äôll go an decide to add it to a playlist an see that it‚Äôs not even in my music. So I‚Äôll add it again. I‚Äôve only notice it since like I said I‚Äôll decide to add it to a playlist an see it has the plus next to add music. But why is it constantly coming out of my music. I have checked an seen that most songs still be in a playlist but not added to my music.. again not understanding these little things. But Please please fix. The little things add up to annoyance when it‚Äôs continuously acting up..\n",
      "I really like this app but I have tried an tried to find out why every time I get a phone call or I go out of my app when I push pause on my music an go back within minutes it goes an refreshes the whole app. I‚Äôm literally in the middle of a song so what is the purpose of refreshing the app I tried to just start putting the music on an old phone I have that‚Äôs just for WiFi but even that if I‚Äôm closer to it an pause it, you can‚Äôt leave the app longer then a minute it seems without it just thinking your not coming back or something. An the other issue is it constantly takes random music that i do listen to often out of my music list. I‚Äôll add a song to my music an sometimes a playlist too, an I‚Äôll be listening to the song randomly later on a station that I choose an I‚Äôll go an decide to add it to a playlist an see that it‚Äôs not even in my music. So I‚Äôll add it again. I‚Äôve only notice it since like I said I‚Äôll decide to add it to a playlist an see it has the plus next to add music. But why is it constantly coming out of my music. I have checked an seen that most songs still be in a playlist but not added to my music.. again not understanding these little things. But Please please fix. The little things add up to annoyance when it‚Äôs continuously acting up..\n"
     ]
    }
   ],
   "source": [
    "x = data.loc[1][\"review\"]\n",
    "\n",
    "# code taken from https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b to remove emojis\n",
    "# this doesn't have the most up to date emojis so we had to find an updated version for some unicode\n",
    "\n",
    "def remove_emojis(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  \n",
    "                               u\"\\u3030\"\n",
    "                               \n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "print(x)\n",
    "print(remove_emojis(x))\n",
    "\n",
    "# henry package to emoji -> word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:04:03.892323Z",
     "start_time": "2021-12-14T13:04:03.875138Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!',\n",
       " ',',\n",
       " '.',\n",
       " ':',\n",
       " '?',\n",
       " 'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'music',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stopwords \n",
    "# we know the reviews are about music, so we remove the stopword music\n",
    "# we also remove punctuation\n",
    "# overall, the revies are clean, although there are emojis present. \n",
    "# for now we will keep emojis as they could be an indication in our classification\n",
    "\n",
    "stopword_list = set(stopwords.words('english') + [\"music\", \".\", \"!\", \"?\", \",\",\":\"])\n",
    "stopword_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:04:59.248618Z",
     "start_time": "2021-12-14T13:04:03.895539Z"
    }
   },
   "outputs": [],
   "source": [
    "#stemming, create an empty list, loop through and stem\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "reviews = data[\"review\"].str.lower()\n",
    "\n",
    "stemmed_list = []\n",
    "for i in reviews:\n",
    "    tokens = nltk.word_tokenize(i)\n",
    "    x = ''\n",
    "    for j in tokens:\n",
    "        x = x + ' ' + stemmer.stem(word = j)\n",
    "    stemmed_list.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:04:59.256862Z",
     "start_time": "2021-12-14T13:04:59.250585Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' i hate mani thing about thi app , but the featur most bothersom to me of late is the keep listen featur . the sleep timer is turn off , but everi hour i get ask am i still listen to music . did i stop the music ? ! i have my devic plug in across the room becaus it ‚Äô s not compat with legrand digit audio ( fix thi too ! ) . so , everi hour when the music stop i have to go press keep listen . i ‚Äô m not oppos to exercis , but i ‚Äô m tri to work , and thi incess disrupt make me want to pay for a differ stream music servic . thi should onli happen if i engag the sleep timer . thi is a useless featur , especi if i am actual stream on wifi and have the stream onli on wifi featur engag or am in offlin mode listen to download music . get rid of thi . anoth huge annoy is the amount of data thi app use even in data saver mode . my daili commut ( 160 minut total stream time ) use 1 gb of data ! mayb it would use less data if the lyric featur could be disabl . final your app support wa useless for provid feedback , so hope someon is read these review .',\n",
       " ' i just want to say that i love love love music . i listen to music liter ever day . but there is one thing that realli get on my nerv . the music unlimit thing is a good idea but , some song that i realli like to listen to are music unlimit , and i love to listen to taylor swift but , a few day ago when i tri to play it , it said that it wa music unlimit . but mayb you could have like ‚Äú pay 10 $ for one week of music unlimit song ‚Äù or ‚Äú pay 20 $ for a year ‚Äù or someth like that . you don ‚Äô t have to that but it ‚Äô s just a suggest . üòä updat : as i said befor i love music and i like the music unlimit idea but it ‚Äô s just kind of expens and when i tri to listen to certain song sometim the day after i listen to them they becom music unlimit when we don ‚Äô t pay for it in the first place . so i wa think that the person want to listen to music but can ‚Äô t becaus it is unlimit could pay , say , $ 20- $ 30 for a whole year or 1/2 a year of unlimit song . i ‚Äô m not tri to cut how much money you get i ‚Äô m just throw out some idea that you could possibl look at and talk it over . i hope that these idea come to be use in the futur .']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_list[5:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:04:59.280275Z",
     "start_time": "2021-12-14T13:04:59.260036Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thi is by far the best music app i have ever ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i realli like thi app but i have tri an tri t...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thi app is great , i 've been use it for a co...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not a bad music app . select is good could be...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thi is one of the most use app on my phone , ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72046</th>\n",
       "      <td>ùê†ùê®ùêöùê≠</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72047</th>\n",
       "      <td>i hate onli ad xd</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72048</th>\n",
       "      <td>i ca n't search and play some song other than...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72049</th>\n",
       "      <td>just work well</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72050</th>\n",
       "      <td>awesom</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72051 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 reviews  ratings\n",
       "0       thi is by far the best music app i have ever ...        5\n",
       "1       i realli like thi app but i have tri an tri t...        4\n",
       "2       thi app is great , i 've been use it for a co...        4\n",
       "3       not a bad music app . select is good could be...        3\n",
       "4       thi is one of the most use app on my phone , ...        2\n",
       "...                                                  ...      ...\n",
       "72046                                               ùê†ùê®ùêöùê≠        5\n",
       "72047                                  i hate onli ad xd        5\n",
       "72048   i ca n't search and play some song other than...        1\n",
       "72049                                     just work well        5\n",
       "72050                                             awesom        5\n",
       "\n",
       "[72051 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_df = pd.DataFrame(stemmed_list, columns = [\"reviews\"])\n",
    "stemmed_df[\"ratings\"] = data[\"rating\"]\n",
    "stemmed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:04:59.315817Z",
     "start_time": "2021-12-14T13:04:59.285435Z"
    }
   },
   "outputs": [],
   "source": [
    "stemmed_df_reviews = stemmed_df[\"reviews\"]\n",
    "stemmed_df_ratings = stemmed_df[\"ratings\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(stemmed_df_reviews, stemmed_df_ratings,\n",
    "                                                    test_size = 0.2, random_state = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:05:06.276819Z",
     "start_time": "2021-12-14T13:04:59.322649Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6649 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4464 accurate.\n"
     ]
    }
   ],
   "source": [
    "# for our vectorization, we start with CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range = (1,2),\n",
    "                            stop_words = stopword_list,\n",
    "                            token_pattern = '(?u)\\\\b[a-zA-Z][a-zA-Z]+\\\\b', # removes emojis btw\n",
    "                            max_features = 2000,\n",
    "                            min_df = 2,\n",
    "                            binary = True)\n",
    "\n",
    "train_X = vectorizer.fit_transform(X_train)\n",
    "lr1 = LogisticRegression(multi_class='multinomial')\n",
    "lr1.fit(train_X, y_train)\n",
    "y_train_pred = lr1.predict(train_X)\n",
    "\n",
    "print(f'Without dimensionality reduction, on the training set, our model is {round(np.mean(y_train_pred == y_train),4)} accurate.')\n",
    "\n",
    "y_test_pred = lr1.predict(vectorizer.fit_transform(X_test))\n",
    "print(f'Without dimensionality reduction, on the testing set, our model is {round(np.mean(y_test_pred == y_test),4)} accurate.')\n",
    "\n",
    "# we get 66% accuracy on the training set and 45% on the testing set\n",
    "# this was just a first pass, in a little we will loop through different parameters and find optimal values\n",
    "# also it is important to note this was with a random state of 25 for train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:05:12.343659Z",
     "start_time": "2021-12-14T13:05:06.279639Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6585 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4801 accurate.\n"
     ]
    }
   ],
   "source": [
    "# what if we use tfidf?\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range = (1,2),\n",
    "                            stop_words = stopword_list,\n",
    "                            token_pattern = '(?u)\\\\b[a-zA-Z][a-zA-Z]+\\\\b', # this will remove emojis btw\n",
    "                            max_features = 2000,\n",
    "                            min_df = 2,\n",
    "                            binary = True)\n",
    "\n",
    "train_X = vectorizer.fit_transform(X_train)\n",
    "lr1 = LogisticRegression(multi_class='multinomial')\n",
    "lr1.fit(train_X, y_train)\n",
    "y_train_pred = lr1.predict(train_X)\n",
    "\n",
    "print(f'Without dimensionality reduction, on the training set, our model is {round(np.mean(y_train_pred == y_train),4)} accurate.')\n",
    "\n",
    "y_test_pred = lr1.predict(vectorizer.fit_transform(X_test))\n",
    "print(f'Without dimensionality reduction, on the testing set, our model is {round(np.mean(y_test_pred == y_test),4)} accurate.')\n",
    "\n",
    "# this is okay even though we are overfitting, and our accuracy on the test set is 48%. \n",
    "# Although BERT accuracy is 61% so this really isn't bad!\n",
    "# this model does better and improves our testing accuracy by about 3% compared to CountVectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:07:24.506559Z",
     "start_time": "2021-12-14T13:05:12.345930Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngrams = (1, 1); max_features = 100; min_df = 2\n",
      "Without dimensionality reduction, on the training set, our model is 0.5698 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4547 accurate.\n",
      "ngrams = (1, 1); max_features = 100; min_df = 3\n",
      "Without dimensionality reduction, on the training set, our model is 0.5698 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4547 accurate.\n",
      "ngrams = (1, 1); max_features = 500; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6247 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4581 accurate.\n",
      "ngrams = (1, 1); max_features = 500; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6247 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4581 accurate.\n",
      "ngrams = (1, 1); max_features = 1000; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6424 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4596 accurate.\n",
      "ngrams = (1, 1); max_features = 1000; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6424 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4533 accurate.\n",
      "ngrams = (1, 1); max_features = 2000; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6616 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4177 accurate.\n",
      "ngrams = (1, 1); max_features = 2000; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6612 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4292 accurate.\n",
      "ngrams = (1, 2); max_features = 100; min_df = 2\n",
      "Without dimensionality reduction, on the training set, our model is 0.5683 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.5079 accurate.\n",
      "ngrams = (1, 2); max_features = 100; min_df = 3\n",
      "Without dimensionality reduction, on the training set, our model is 0.5683 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.5079 accurate.\n",
      "ngrams = (1, 2); max_features = 500; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6226 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.505 accurate.\n",
      "ngrams = (1, 2); max_features = 500; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6226 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4935 accurate.\n",
      "ngrams = (1, 2); max_features = 1000; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6422 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4664 accurate.\n",
      "ngrams = (1, 2); max_features = 1000; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6421 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4756 accurate.\n",
      "ngrams = (1, 2); max_features = 2000; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6649 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4464 accurate.\n",
      "ngrams = (1, 2); max_features = 2000; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6653 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4521 accurate.\n",
      "ngrams = (2, 2); max_features = 100; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.5091 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4522 accurate.\n",
      "ngrams = (2, 2); max_features = 100; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.5091 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4522 accurate.\n",
      "ngrams = (2, 2); max_features = 500; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.5557 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4658 accurate.\n",
      "ngrams = (2, 2); max_features = 500; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.5556 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4797 accurate.\n",
      "ngrams = (2, 2); max_features = 1000; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.5817 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4728 accurate.\n",
      "ngrams = (2, 2); max_features = 1000; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.5814 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4732 accurate.\n",
      "ngrams = (2, 2); max_features = 2000; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6116 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4525 accurate.\n",
      "ngrams = (2, 2); max_features = 2000; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6114 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4495 accurate.\n",
      "ngrams = (3, 3); max_features = 100; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.4789 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4566 accurate.\n",
      "ngrams = (3, 3); max_features = 100; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.4789 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4723 accurate.\n",
      "ngrams = (3, 3); max_features = 500; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.503 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4633 accurate.\n",
      "ngrams = (3, 3); max_features = 500; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.503 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.468 accurate.\n",
      "ngrams = (3, 3); max_features = 1000; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.5233 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4542 accurate.\n",
      "ngrams = (3, 3); max_features = 1000; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.5228 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4609 accurate.\n",
      "ngrams = (3, 3); max_features = 2000; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.5459 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4511 accurate.\n",
      "ngrams = (3, 3); max_features = 2000; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.5468 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4538 accurate.\n"
     ]
    }
   ],
   "source": [
    "# lets loop and find our best model for CountVectorize\n",
    "\n",
    "ngrams = [(1,1), (1,2), (2,2), (3,3)]\n",
    "max_features = [100, 500,1000,2000]\n",
    "min_df = [2, 3]\n",
    "\n",
    "champion_model = \"\"\n",
    "champion_model_test_score = 0\n",
    "\n",
    "for i in ngrams:\n",
    "    for j in max_features:\n",
    "        for k in min_df:\n",
    "                print(f'ngrams = {i}; max_features = {j}; min_df = {k}')\n",
    "                vectorizer = CountVectorizer(ngram_range = i,\n",
    "                                            stop_words = stopword_list,\n",
    "                                            token_pattern = '(?u)\\\\b[a-zA-Z][a-zA-Z]+\\\\b', # this will remove emojis btw\n",
    "                                            max_features = j,\n",
    "                                            min_df = k,\n",
    "                                            binary = True)\n",
    "\n",
    "                train_X = vectorizer.fit_transform(X_train)\n",
    "                lr1 = LogisticRegression(multi_class='multinomial')\n",
    "                lr1.fit(train_X, y_train)\n",
    "                y_train_pred = lr1.predict(train_X)\n",
    "\n",
    "                print(f'Without dimensionality reduction, on the training set, our model is {round(np.mean(y_train_pred == y_train),4)} accurate.')\n",
    "\n",
    "                y_test_pred = lr1.predict(vectorizer.fit_transform(X_test))\n",
    "                print(f'Without dimensionality reduction, on the testing set, our model is {round(np.mean(y_test_pred == y_test),4)} accurate.')\n",
    "                if round(np.mean(y_test_pred == y_test),4) > champion_model_test_score:\n",
    "                    champion_model_test_score = round(np.mean(y_test_pred == y_test),4)\n",
    "                    champion_model = f'ngram = {i} ; max_features = {j} ; min_df = {k}'\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:07:24.513204Z",
     "start_time": "2021-12-14T13:07:24.508911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For CountVectorization, our champion model is ngram = (1, 2) ; max_features = 100 ; min_df = 2 with an accuracy of 0.5079 on the testing set\n"
     ]
    }
   ],
   "source": [
    "print(f'For CountVectorization, our champion model is {champion_model} with an accuracy of \\\n",
    "{champion_model_test_score} on the testing set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:09:45.087724Z",
     "start_time": "2021-12-14T13:07:24.516937Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngrams = (1, 1); max_features = 100; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.5782 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4299 accurate.\n",
      "ngrams = (1, 1); max_features = 100; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.5782 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4299 accurate.\n",
      "ngrams = (1, 1); max_features = 500; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6287 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.471 accurate.\n",
      "ngrams = (1, 1); max_features = 500; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6287 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.471 accurate.\n",
      "ngrams = (1, 1); max_features = 1000; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6416 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4592 accurate.\n",
      "ngrams = (1, 1); max_features = 1000; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6418 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4324 accurate.\n",
      "ngrams = (1, 1); max_features = 2000; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6526 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4318 accurate.\n",
      "ngrams = (1, 1); max_features = 2000; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6533 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4353 accurate.\n",
      "ngrams = (1, 2); max_features = 100; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.5771 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.5106 accurate.\n",
      "ngrams = (1, 2); max_features = 100; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.5771 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.5106 accurate.\n",
      "ngrams = (1, 2); max_features = 500; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6259 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.5029 accurate.\n",
      "ngrams = (1, 2); max_features = 500; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6259 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4905 accurate.\n",
      "ngrams = (1, 2); max_features = 1000; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6434 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4519 accurate.\n",
      "ngrams = (1, 2); max_features = 1000; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6434 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4838 accurate.\n",
      "ngrams = (1, 2); max_features = 2000; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6585 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4801 accurate.\n",
      "ngrams = (1, 2); max_features = 2000; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6587 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4747 accurate.\n",
      "ngrams = (2, 2); max_features = 100; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.5116 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4463 accurate.\n",
      "ngrams = (2, 2); max_features = 100; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.5116 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4463 accurate.\n",
      "ngrams = (2, 2); max_features = 500; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.5603 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4656 accurate.\n",
      "ngrams = (2, 2); max_features = 500; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.5602 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4809 accurate.\n",
      "ngrams = (2, 2); max_features = 1000; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.5849 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4698 accurate.\n",
      "ngrams = (2, 2); max_features = 1000; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.5851 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4635 accurate.\n",
      "ngrams = (2, 2); max_features = 2000; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6102 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4485 accurate.\n",
      "ngrams = (2, 2); max_features = 2000; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.6095 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4486 accurate.\n",
      "ngrams = (3, 3); max_features = 100; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.4787 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.459 accurate.\n",
      "ngrams = (3, 3); max_features = 100; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.4787 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4714 accurate.\n",
      "ngrams = (3, 3); max_features = 500; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.5045 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4658 accurate.\n",
      "ngrams = (3, 3); max_features = 500; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.5045 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4688 accurate.\n",
      "ngrams = (3, 3); max_features = 1000; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.523 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4546 accurate.\n",
      "ngrams = (3, 3); max_features = 1000; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.5226 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4646 accurate.\n",
      "ngrams = (3, 3); max_features = 2000; min_df = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.543 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4512 accurate.\n",
      "ngrams = (3, 3); max_features = 2000; min_df = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.5431 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.4576 accurate.\n"
     ]
    }
   ],
   "source": [
    "# lets loop and find our best model\n",
    "ngrams = [(1,1), (1,2), (2,2), (3,3)]\n",
    "max_features = [100, 500,1000,2000]\n",
    "min_df = [2, 3]\n",
    "\n",
    "champion_model = \"\"\n",
    "champion_model_test_score = 0\n",
    "\n",
    "for i in ngrams:\n",
    "    for j in max_features:\n",
    "        for k in min_df:\n",
    "                print(f'ngrams = {i}; max_features = {j}; min_df = {k}')\n",
    "                vectorizer = TfidfVectorizer(ngram_range = i,\n",
    "                                            stop_words = stopword_list,\n",
    "                                            token_pattern = '(?u)\\\\b[a-zA-Z][a-zA-Z]+\\\\b', # this will remove emojis btw\n",
    "                                            max_features = j,\n",
    "                                            min_df = k,\n",
    "                                            binary = True)\n",
    "\n",
    "                train_X = vectorizer.fit_transform(X_train)\n",
    "                lr1 = LogisticRegression(multi_class='multinomial')\n",
    "                lr1.fit(train_X, y_train)\n",
    "                y_train_pred = lr1.predict(train_X)\n",
    "\n",
    "                print(f'Without dimensionality reduction, on the training set, our model is {round(np.mean(y_train_pred == y_train),4)} accurate.')\n",
    "\n",
    "                y_test_pred = lr1.predict(vectorizer.fit_transform(X_test))\n",
    "                print(f'Without dimensionality reduction, on the testing set, our model is {round(np.mean(y_test_pred == y_test),4)} accurate.')\n",
    "                if round(np.mean(y_test_pred == y_test),4) > champion_model_test_score:\n",
    "                    champion_model_test_score = round(np.mean(y_test_pred == y_test),4)\n",
    "                    champion_model = f'ngram = {i} ; max_features = {j} ; min_df = {k}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:09:45.096440Z",
     "start_time": "2021-12-14T13:09:45.090033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For TfIdfVectorization, our champion model is ngram = (1, 2) ; max_features = 100 ; min_df = 2 with an accuracy of 0.5106 on the testing set\n"
     ]
    }
   ],
   "source": [
    "print(f'For TfIdfVectorization, our champion model is {champion_model} with an accuracy of \\\n",
    "{champion_model_test_score} on the testing set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways:\n",
    "\n",
    "- Both CountVectorize and TfIdf vectorization have accuracies revolving around 51% on the testing set.\n",
    "- Honestly, this is pretty good considering BERT gave 61%!\n",
    "- Both vectorizers had highest accuracy for ngram of (1,2), max_features = 100, and min_df = 2\n",
    "- Let's now analyze our second accuracy metric, which is \"off by 1\" accuracy (if our model classifies a review as a 4 instead of 5 or a 2 instead of a 1 for example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:09:49.060584Z",
     "start_time": "2021-12-14T13:09:45.101022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.5683 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.5079 accurate.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(stemmed_df_reviews, stemmed_df_ratings,\n",
    "                                                    test_size = 0.2, random_state = 25)\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range = (1,2),\n",
    "                            stop_words = stopword_list,\n",
    "                            token_pattern = '(?u)\\\\b[a-zA-Z][a-zA-Z]+\\\\b', # this will remove emojis btw\n",
    "                            max_features = 100,\n",
    "                            min_df = 2,\n",
    "                            binary = True)\n",
    "\n",
    "train_X = vectorizer.fit_transform(X_train)\n",
    "lr1 = LogisticRegression(multi_class='multinomial')\n",
    "lr1.fit(train_X, y_train)\n",
    "y_train_pred = lr1.predict(train_X)\n",
    "\n",
    "print(f'Without dimensionality reduction, on the training set, our model is {round(np.mean(y_train_pred == y_train),4)} accurate.')\n",
    "\n",
    "y_test_pred = lr1.predict(vectorizer.fit_transform(X_test))\n",
    "print(f'Without dimensionality reduction, on the testing set, our model is {round(np.mean(y_test_pred == y_test),4)} accurate.')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:09:49.098399Z",
     "start_time": "2021-12-14T13:09:49.062534Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The off by 1 accuracy for our testing set for our CountVectorizer champion model is 0.67102\n"
     ]
    }
   ],
   "source": [
    "# 1 off accuracy, Count Vectorization\n",
    "test_frame = pd.DataFrame(X_test)\n",
    "test_frame[\"actual_ratings\"] = y_test\n",
    "test_frame[\"predicted_ratings\"] = y_test_pred\n",
    "\n",
    "test_frame[\"difference\"] = abs(test_frame[\"actual_ratings\"]-test_frame[\"predicted_ratings\"]) <= 1\n",
    "\n",
    "print(f'The off by 1 accuracy for our testing set for our CountVectorizer champion model is \\\n",
    "{round(sum(test_frame[\"difference\"])/len(test_frame[\"difference\"]),5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:09:53.459193Z",
     "start_time": "2021-12-14T13:09:49.100623Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without dimensionality reduction, on the training set, our model is 0.5771 accurate.\n",
      "Without dimensionality reduction, on the testing set, our model is 0.5106 accurate.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(stemmed_df_reviews, stemmed_df_ratings,\n",
    "                                                    test_size = 0.2, random_state = 25)\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range = (1,2),\n",
    "                            stop_words = stopword_list,\n",
    "                            token_pattern = '(?u)\\\\b[a-zA-Z][a-zA-Z]+\\\\b', # this will remove emojis btw\n",
    "                            max_features = 100,\n",
    "                            min_df = 2,\n",
    "                            binary = True)\n",
    "\n",
    "train_X = vectorizer.fit_transform(X_train)\n",
    "lr1 = LogisticRegression(multi_class='multinomial')\n",
    "lr1.fit(train_X, y_train)\n",
    "y_train_pred = lr1.predict(train_X)\n",
    "\n",
    "print(f'Without dimensionality reduction, on the training set, our model is {round(np.mean(y_train_pred == y_train),4)} accurate.')\n",
    "\n",
    "y_test_pred = lr1.predict(vectorizer.fit_transform(X_test))\n",
    "print(f'Without dimensionality reduction, on the testing set, our model is {round(np.mean(y_test_pred == y_test),4)} accurate.')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:09:53.475319Z",
     "start_time": "2021-12-14T13:09:53.461664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The off by 1 accuracy for our testing set for our CountVectorizer champion model is 0.66921\n"
     ]
    }
   ],
   "source": [
    "# 1 off accuracy, TfIdf Vectorization\n",
    "test_frame = pd.DataFrame(X_test)\n",
    "test_frame[\"actual_ratings\"] = y_test\n",
    "test_frame[\"predicted_ratings\"] = y_test_pred\n",
    "\n",
    "test_frame[\"difference\"] = abs(test_frame[\"actual_ratings\"]-test_frame[\"predicted_ratings\"]) <= 1\n",
    "\n",
    "print(f'The off by 1 accuracy for our testing set for our CountVectorizer champion model is \\\n",
    "{round(sum(test_frame[\"difference\"])/len(test_frame[\"difference\"]),5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways:\n",
    "- Our Count Vectorizer, on our testing set, had an accuracy of 50.79%. If we look at 1 off accuracy, it was 67.1% accurate, or about 2/3.\n",
    "- Our TfIdf Vectorizer, on our testing set, had an accuracy of 51.06%. If we look at 1 off accuracy, it was 66.92% accurate, also about 2/3\n",
    "#### The big takeaway here is that we generally classify about half correctly, and this jumps up to 2/3 if we look at \"within 1\" ratings. \n",
    "\n",
    "\n",
    "Before we jump in and look into confusion matrix and AUROC, let's first test different random states for our train_test_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:10:32.671731Z",
     "start_time": "2021-12-14T13:09:53.477656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a random state of 1, our test set accuracy is 0.424\n",
      "With a random state of 7, our test set accuracy is 0.4368\n",
      "With a random state of 19, our test set accuracy is 0.4796\n",
      "With a random state of 25, our test set accuracy is 0.5079\n",
      "With a random state of 31, our test set accuracy is 0.564\n",
      "With a random state of 44, our test set accuracy is 0.4633\n",
      "With a random state of 67, our test set accuracy is 0.4902\n",
      "With a random state of 125, our test set accuracy is 0.4584\n",
      "With a random state of 177, our test set accuracy is 0.4333\n",
      "With a random state of 255, our test set accuracy is 0.4723\n",
      "Our average accuracy is 0.47298\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "random_list = [1, 7, 19, 25, 31, 44, 67, 125, 177, 255]\n",
    "for i in random_list:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(stemmed_df_reviews, stemmed_df_ratings,\n",
    "                                                        test_size = 0.2, random_state = i)\n",
    "\n",
    "    vectorizer = CountVectorizer(ngram_range = (1,2),\n",
    "                                stop_words = stopword_list,\n",
    "                                token_pattern = '(?u)\\\\b[a-zA-Z][a-zA-Z]+\\\\b', # this will remove emojis btw\n",
    "                                max_features = 100,\n",
    "                                min_df = 2,\n",
    "                                binary = True)\n",
    "    train_X = vectorizer.fit_transform(X_train)\n",
    "    lr1 = LogisticRegression(multi_class='multinomial')\n",
    "    lr1.fit(train_X, y_train)\n",
    "    y_train_pred = lr1.predict(train_X)\n",
    "    y_test_pred = lr1.predict(vectorizer.fit_transform(X_test))\n",
    "    accuracy = round(np.mean(y_test_pred == y_test),4)\n",
    "    print(f'With a random state of {i}, our test set accuracy is {accuracy}')\n",
    "    total += accuracy\n",
    "\n",
    "print(f'Our average accuracy is {round(total/len(random_list), 5)}')\n",
    "\n",
    "# it looks like we got a little lucky choosing 25 as our random state, but we still have averaged 47.3% \n",
    "# accuracy on the testing set\n",
    "\n",
    "# we select the closest value to this average for our final model, and use random state 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:11:17.731190Z",
     "start_time": "2021-12-14T13:10:32.673834Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a random state of 1, our test set accuracy is 0.4285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a random state of 7, our test set accuracy is 0.4254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a random state of 19, our test set accuracy is 0.4826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a random state of 25, our test set accuracy is 0.5106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a random state of 31, our test set accuracy is 0.5708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a random state of 44, our test set accuracy is 0.4582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a random state of 67, our test set accuracy is 0.4893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a random state of 125, our test set accuracy is 0.4474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a random state of 177, our test set accuracy is 0.4142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a random state of 255, our test set accuracy is 0.4697\n",
      "Our average accuracy is 0.46967\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "random_list = [1, 7, 19, 25, 31, 44, 67, 125, 177, 255]\n",
    "for i in random_list:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(stemmed_df_reviews, stemmed_df_ratings,\n",
    "                                                        test_size = 0.2, random_state = i)\n",
    "\n",
    "    vectorizer = TfidfVectorizer(ngram_range = (1,2),\n",
    "                                stop_words = stopword_list,\n",
    "                                token_pattern = '(?u)\\\\b[a-zA-Z][a-zA-Z]+\\\\b', # this will remove emojis btw\n",
    "                                max_features = 100,\n",
    "                                min_df = 2,\n",
    "                                binary = True)\n",
    "    train_X = vectorizer.fit_transform(X_train)\n",
    "    lr1 = LogisticRegression(multi_class='multinomial')\n",
    "    lr1.fit(train_X, y_train)\n",
    "    y_train_pred = lr1.predict(train_X)\n",
    "    y_test_pred = lr1.predict(vectorizer.fit_transform(X_test))\n",
    "    accuracy = round(np.mean(y_test_pred == y_test),4)\n",
    "    print(f'With a random state of {i}, our test set accuracy is {accuracy}')\n",
    "    total += accuracy\n",
    "\n",
    "print(f'Our average accuracy is {round(total/len(random_list), 5)}')\n",
    "\n",
    "# again, it seems like originally picking 25 was a little lucky, but here we obtain an average 46.97% accuracy on\n",
    "# the testing set\n",
    "\n",
    "# we will take random seed of 255 because this value is closest to the average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "- Our final choice is random seed of 255, since it is closest to the average scores of the 10 random seeds we chose \n",
    "- Let's first look at accuracy for Count and TfIdf vectorization.\n",
    "- Then, we will look at \"1 off accuracy\"\n",
    "- Finally, we will look at the confusion matrix and AUROC curves for both of these models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:17:07.335826Z",
     "start_time": "2021-12-14T13:17:02.969456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our test set accuracy is 0.4723\n",
      "The off by 1 accuracy for our testing set for our CountVectorizer champion model is 0.64895\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(stemmed_df_reviews, stemmed_df_ratings,\n",
    "                                                    test_size = 0.2, random_state = 255)\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range = (1,2),\n",
    "                            stop_words = stopword_list,\n",
    "                            token_pattern = '(?u)\\\\b[a-zA-Z][a-zA-Z]+\\\\b', # this will remove emojis btw\n",
    "                            max_features = 100,\n",
    "                            min_df = 2,\n",
    "                            binary = True)\n",
    "\n",
    "train_X = vectorizer.fit_transform(X_train)\n",
    "lr1 = LogisticRegression(multi_class='multinomial')\n",
    "lr1.fit(train_X, y_train)\n",
    "y_train_pred = lr1.predict(train_X)\n",
    "y_test_pred = lr1.predict(vectorizer.fit_transform(X_test))\n",
    "accuracy = round(np.mean(y_test_pred == y_test),4)\n",
    "print(f'Our test set accuracy is {accuracy}')\n",
    "\n",
    "test_frame = pd.DataFrame(X_test)\n",
    "test_frame[\"actual_ratings\"] = y_test\n",
    "test_frame[\"predicted_ratings\"] = y_test_pred\n",
    "test_frame[\"difference\"] = abs(test_frame[\"actual_ratings\"]-test_frame[\"predicted_ratings\"]) <= 1\n",
    "off1_accuracy = round(sum(test_frame[\"difference\"])/len(test_frame[\"difference\"]),5)\n",
    "print(f'The off by 1 accuracy for our testing set for our CountVectorizer champion model is \\\n",
    "{off1_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is actually pretty solid, about 2/3 of the reviews are classified within 1 of their actual score with our CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:28:29.522297Z",
     "start_time": "2021-12-14T13:28:29.480503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our confusion matrix looks like \n",
      " \n",
      "  [[ 977   30  246  293 1749]\n",
      " [ 331   17  159  192  481]\n",
      " [ 262   16  229  281  626]\n",
      " [ 282    6  209  359 1014]\n",
      " [ 638   14  270  505 5225]] \n",
      "\n",
      "For the 3295 1 star reviews, precision is 0.3924, recall is 0.2965, and our F1 score would be 0.3378 \n",
      "\n",
      "For the 1180 2 star reviews, precision is 0.2048, recall is 0.0144, and our F1 score would be 0.0269 \n",
      "\n",
      "For the 1414 3 star reviews, precision is 0.2058, recall is 0.162, and our F1 score would be 0.1813 \n",
      "\n",
      "For the 1870 4 star reviews, precision is 0.2202, recall is 0.192, and our F1 score would be 0.2051 \n",
      "\n",
      "For the 6652 5 star reviews, precision is 0.5745, recall is 0.7855, and our F1 score would be 0.6636 \n",
      "\n",
      "\n",
      "Overall precision is 0.4724; overall recall is 0.4724; overall F1 is 0.6636\n"
     ]
    }
   ],
   "source": [
    "print(f'Our confusion matrix looks like \\n \\n  {confusion_matrix(y_test, y_test_pred)} \\n')\n",
    "\n",
    "x = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "stars = [1,2,3,4,5]\n",
    "\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "total_actual_list = []\n",
    "total_predicted_list = []\n",
    "\n",
    "for i in stars:\n",
    "    precision = round(x[i-1,i-1]/sum(x[0:5,i-1]),4)\n",
    "    precision_list.append(precision)\n",
    "    recall = round(x[i-1,i-1]/sum(x[i-1,0:5]),4)\n",
    "    recall_list.append(recall)\n",
    "    total_actual_list.append(sum(x[i-1,0:5]))\n",
    "    total_predicted_list.append(sum(x[0:5,i-1]))\n",
    "    F1 = round(2*recall*precision/(precision+recall),4)\n",
    "    print(f'For the {sum(x[i-1,0:5])} {i} star reviews, precision is {precision}, recall is {recall}, and our F1 score would be {F1} \\n')\n",
    "\n",
    "p = 0\n",
    "for i in range(len(precision_list)):\n",
    "    p += precision_list[i]*total_predicted_list[i]\n",
    "final_prec = round(p/sum(total_predicted_list),4)\n",
    "\n",
    "r = 0\n",
    "for i in range(len(recall_list)):\n",
    "    r += recall_list[i]*total_actual_list[i]\n",
    "final_rec = round(r/sum(total_actual_list), 4)\n",
    "\n",
    "final_F1 = round(2*final_rec*final_prec/(final_prec+final_rec),4)\n",
    "print(f'\\nOverall precision is {final_prec}; overall recall is {final_rec}; overall F1 is {F1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Looking at our confusion matrix, the most common error is our model classifying reviews as 5 star when they are in fact 1 star reviews, or 5 star when they are 4 star reviews. \n",
    "- We have really bad recall for 2 star reviews\n",
    "- 5 star reviews have the highet F1 score as well as recall of 78.55%!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:22:25.414348Z",
     "start_time": "2021-12-14T13:22:25.411860Z"
    }
   },
   "outputs": [],
   "source": [
    "# what about AUROC?\n",
    "#problem since not 2-D, ways around it but complicated\n",
    "#print(f'Our AUROC is {round(roc_auc_score(y_test, y_test_pred),4)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:11:28.682611Z",
     "start_time": "2021-12-14T13:11:22.991842Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our test set accuracy is 0.4697\n",
      "The off by 1 accuracy for our testing set for our CountVectorizer champion model is 0.63625\n"
     ]
    }
   ],
   "source": [
    "# lets do the same for TfIdf\n",
    "X_train, X_test, y_train, y_test = train_test_split(stemmed_df_reviews, stemmed_df_ratings,\n",
    "                                                    test_size = 0.2, random_state = 255)\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range = (1,2),\n",
    "                            stop_words = stopword_list,\n",
    "                            token_pattern = '(?u)\\\\b[a-zA-Z][a-zA-Z]+\\\\b', # this will remove emojis btw\n",
    "                            max_features = 100,\n",
    "                            min_df = 2,\n",
    "                            binary = True)\n",
    "\n",
    "train_X = vectorizer.fit_transform(X_train)\n",
    "lr1 = LogisticRegression(multi_class='multinomial')\n",
    "lr1.fit(train_X, y_train)\n",
    "y_train_pred = lr1.predict(train_X)\n",
    "y_test_pred = lr1.predict(vectorizer.fit_transform(X_test))\n",
    "accuracy = round(np.mean(y_test_pred == y_test),4)\n",
    "print(f'Our test set accuracy is {accuracy}')\n",
    "\n",
    "test_frame = pd.DataFrame(X_test)\n",
    "test_frame[\"actual_ratings\"] = y_test\n",
    "test_frame[\"predicted_ratings\"] = y_test_pred\n",
    "test_frame[\"difference\"] = abs(test_frame[\"actual_ratings\"]-test_frame[\"predicted_ratings\"]) <= 1\n",
    "off1_accuracy = round(sum(test_frame[\"difference\"])/len(test_frame[\"difference\"]),5)\n",
    "print(f'The off by 1 accuracy for our testing set for our CountVectorizer champion model is \\\n",
    "{off1_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is actually pretty solid, about 2/3 of the reviews are classified within 1 of their actual score with our TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:11:28.730791Z",
     "start_time": "2021-12-14T13:11:28.687957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our confusion matrix looks like \n",
      " \n",
      "  [[1311    8  214  244 1518]\n",
      " [ 420   10  109  180  461]\n",
      " [ 366    7  160  224  657]\n",
      " [ 371    7  142  292 1058]\n",
      " [ 944    6  274  432 4996]] \n",
      "\n",
      "For the 3295 1 star reviews, precision is 0.3842, recall is 0.3979, and our F1 score would be 0.3909 \n",
      "\n",
      "For the 1180 2 star reviews, precision is 0.2632, recall is 0.0085, and our F1 score would be 0.0165 \n",
      "\n",
      "For the 1414 3 star reviews, precision is 0.178, recall is 0.1132, and our F1 score would be 0.1384 \n",
      "\n",
      "For the 1870 4 star reviews, precision is 0.2128, recall is 0.1561, and our F1 score would be 0.1801 \n",
      "\n",
      "For the 6652 5 star reviews, precision is 0.5749, recall is 0.7511, and our F1 score would be 0.6513 \n",
      "\n",
      "\n",
      "Overall precision is 0.4697; overall recall is 0.4697; overall F1 is 0.6513\n"
     ]
    }
   ],
   "source": [
    "print(f'Our confusion matrix looks like \\n \\n  {confusion_matrix(y_test, y_test_pred)} \\n')\n",
    "\n",
    "x = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "stars = [1,2,3,4,5]\n",
    "\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "total_actual_list = []\n",
    "total_predicted_list = []\n",
    "\n",
    "for i in stars:\n",
    "    precision = round(x[i-1,i-1]/sum(x[0:5,i-1]),4)\n",
    "    precision_list.append(precision)\n",
    "    recall = round(x[i-1,i-1]/sum(x[i-1,0:5]),4)\n",
    "    recall_list.append(recall)\n",
    "    total_actual_list.append(sum(x[i-1,0:5]))\n",
    "    total_predicted_list.append(sum(x[0:5,i-1]))\n",
    "    F1 = round(2*recall*precision/(precision+recall),4)\n",
    "    print(f'For the {sum(x[i-1,0:5])} {i} star reviews, precision is {precision}, recall is {recall}, and our F1 score would be {F1} \\n')\n",
    "\n",
    "p = 0\n",
    "for i in range(len(precision_list)):\n",
    "    p += precision_list[i]*total_predicted_list[i]\n",
    "final_prec = round(p/sum(total_predicted_list),4)\n",
    "\n",
    "r = 0\n",
    "for i in range(len(recall_list)):\n",
    "    r += recall_list[i]*total_actual_list[i]\n",
    "final_rec = round(r/sum(total_actual_list), 4)\n",
    "\n",
    "final_F1 = round(2*final_rec*final_prec/(final_prec+final_rec),4)\n",
    "print(f'\\nOverall precision is {final_prec}; overall recall is {final_rec}; overall F1 is {F1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count and TfIdf Vectorization final comments\n",
    "\n",
    "While we didn't achieve our goal of beating our BERT model (61% accuracy, 85% \"1-off\" accuracy), we managed to build a couple of models that get close.\n",
    "\n",
    "- Our Count Vectorizer model, on the test set, achieves 47.23% accuracy with \"1-off\" accuracy of 64.9%. The final F1-score is 0.664. \n",
    "- Our TfIdf Vectorizer model, on the test set, achieves 46.97% accuracy, with \"1-off\" accuracy of 63.63%. The final F1-score is 0.651\n",
    "\n",
    "Not too shabby!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:31:37.563219Z",
     "start_time": "2021-12-14T13:31:37.559623Z"
    }
   },
   "source": [
    "# Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:38:10.708556Z",
     "start_time": "2021-12-14T13:38:10.705282Z"
    }
   },
   "outputs": [],
   "source": [
    "#!spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T13:47:22.852114Z",
     "start_time": "2021-12-14T13:47:22.409365Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "spacy_review = data[\"review\"]\n",
    "spacy_rating = data[\"rating\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(spacy_review, spacy_rating,\n",
    "                                                    test_size = 0.2, random_state = 199)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T14:31:52.665301Z",
     "start_time": "2021-12-14T14:25:02.724404Z"
    }
   },
   "outputs": [],
   "source": [
    "helper_X_train = list(X_train.apply(lambda x: nlp(x).vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T14:40:09.763902Z",
     "start_time": "2021-12-14T14:40:07.441373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Spacy, our model is 0.526 accurate on our training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyfarhat/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "spacy_lr = LogisticRegression(multi_class='multinomial')\n",
    "\n",
    "spacy_lr.fit(helper_X_train, y_train)\n",
    "train_prediction = spacy_lr.predict(helper_X_train)\n",
    "\n",
    "train_acc = round(np.mean(train_prediction == y_train), 4)\n",
    "print(f'Using Spacy, our model is {train_acc} accurate on our training set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T14:52:16.080580Z",
     "start_time": "2021-12-14T14:49:38.563983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Spacy, our model is 0.5274 accurate on our testing set\n"
     ]
    }
   ],
   "source": [
    "helper_X_test = list(X_test.apply(lambda x: nlp(x).vector))\n",
    "test_prediction = spacy_lr.predict(helper_X_test)\n",
    "test_acc = round(np.mean(test_prediction == y_test), 4)\n",
    "print(f'Using Spacy, our model is {test_acc} accurate on our testing set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T14:54:49.411766Z",
     "start_time": "2021-12-14T14:54:49.394000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1488,    3,   11,    6, 1728],\n",
       "       [ 428,    1,    2,    6,  704],\n",
       "       [ 345,    1,    5,    5, 1068],\n",
       "       [ 280,    0,    3,   20, 1644],\n",
       "       [ 548,    1,   12,   16, 6086]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, test_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "\n",
    "- very close training and testing accuracy, sitting at around 53%\n",
    "- this is pretty good considering BERT achieves 61%.\n",
    "- the confusion matrix looks a lot cleaner than the bag of words models, however we are predicting mostly 1/5 star reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T14:57:49.602986Z",
     "start_time": "2021-12-14T14:57:49.554190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our confusion matrix looks like \n",
      " \n",
      "  [[1488    3   11    6 1728]\n",
      " [ 428    1    2    6  704]\n",
      " [ 345    1    5    5 1068]\n",
      " [ 280    0    3   20 1644]\n",
      " [ 548    1   12   16 6086]] \n",
      "\n",
      "here1\n",
      "For the 3236 1 star reviews, precision is 0.4817, recall is 0.4598, and our F1 score would be 0.4705 \n",
      "\n",
      "For the 1141 2 star reviews, precision is 0.1667, recall is 0.0009, and our F1 score would be 0.0018 \n",
      "\n",
      "For the 1424 3 star reviews, precision is 0.1515, recall is 0.0035, and our F1 score would be 0.0068 \n",
      "\n",
      "For the 1947 4 star reviews, precision is 0.3774, recall is 0.0103, and our F1 score would be 0.0201 \n",
      "\n",
      "For the 6663 5 star reviews, precision is 0.5419, recall is 0.9134, and our F1 score would be 0.6802 \n",
      "\n",
      "\n",
      "Overall precision is 0.5273; overall recall is 0.5274; overall F1 is 0.6802\n"
     ]
    }
   ],
   "source": [
    "print(f'Our confusion matrix looks like \\n \\n  {confusion_matrix(y_test, test_prediction)} \\n')\n",
    "\n",
    "x = confusion_matrix(y_test, test_prediction)\n",
    "print('here1')\n",
    "stars = [1,2,3,4,5]\n",
    "\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "total_actual_list = []\n",
    "total_predicted_list = []\n",
    "\n",
    "for i in stars:\n",
    "    precision = round(x[i-1,i-1]/sum(x[0:5,i-1]),4)\n",
    "    precision_list.append(precision)\n",
    "    recall = round(x[i-1,i-1]/sum(x[i-1,0:5]),4)\n",
    "    recall_list.append(recall)\n",
    "    total_actual_list.append(sum(x[i-1,0:5]))\n",
    "    total_predicted_list.append(sum(x[0:5,i-1]))\n",
    "    F1 = round(2*recall*precision/(precision+recall),4)\n",
    "    print(f'For the {sum(x[i-1,0:5])} {i} star reviews, precision is {precision}, recall is {recall}, and our F1 score would be {F1} \\n')\n",
    "\n",
    "p = 0\n",
    "for i in range(len(precision_list)):\n",
    "    p += precision_list[i]*total_predicted_list[i]\n",
    "final_prec = round(p/sum(total_predicted_list),4)\n",
    "\n",
    "r = 0\n",
    "for i in range(len(recall_list)):\n",
    "    r += recall_list[i]*total_actual_list[i]\n",
    "final_rec = round(r/sum(total_actual_list), 4)\n",
    "\n",
    "final_F1 = round(2*final_rec*final_prec/(final_prec+final_rec),4)\n",
    "print(f'\\nOverall precision is {final_prec}; overall recall is {final_rec}; overall F1 is {F1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **This model performs slightly better on the testing set than our Count/TFidf vectorization models. However, if we look at the \"1-off\" metric:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T15:06:29.387047Z",
     "start_time": "2021-12-14T15:06:29.365419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For some reason I need to print this for the cell to run, probably due to spacy taking hella long to run \n",
      "\n",
      "                                                  review  actual_ratings  \\\n",
      "10754  It didn‚Äôt take me long to decide to upgrade to...               5   \n",
      "11304  It could be better on mobile for sure. I liste...               4   \n",
      "20726  I have made my prime member subscription for 1...               1   \n",
      "27304  While exiting the car mode, the app keeps comi...               3   \n",
      "13028  I enjoy the rest of the app entirely, really. ...               5   \n",
      "9520       Some of the music stops working after a month               5   \n",
      "19218  So this is probably gonna be the shortest revi...               4   \n",
      "26910  Good if you want to pay a subscription, terrib...               2   \n",
      "10514  The playlists are great, suggestions are gener...               2   \n",
      "50843  First of all its not ad free you have to pay f...               1   \n",
      "\n",
      "       predicted_ratings  difference  \n",
      "10754                  5        True  \n",
      "11304                  5        True  \n",
      "20726                  5       False  \n",
      "27304                  1       False  \n",
      "13028                  5        True  \n",
      "9520                   5        True  \n",
      "19218                  5        True  \n",
      "26910                  5       False  \n",
      "10514                  5       False  \n",
      "50843                  5       False  \n",
      "The off by 1 accuracy for our testing set for our Spacy model is 0.67324\n"
     ]
    }
   ],
   "source": [
    "print(\"For some reason I need to print this for the cell to run, probably due to spacy taking hella long to run \\n\")\n",
    "\n",
    "test_frame = pd.DataFrame(X_test)\n",
    "\n",
    "\n",
    "test_frame[\"actual_ratings\"] = y_test\n",
    "test_frame[\"predicted_ratings\"] = test_prediction\n",
    "test_frame[\"difference\"] = abs(test_frame[\"actual_ratings\"]-test_frame[\"predicted_ratings\"]) <= 1\n",
    "\n",
    "print(test_frame.head(10))\n",
    "\n",
    "print(f'The off by 1 accuracy for our testing set for our Spacy model is \\\n",
    "{round(sum(test_frame[\"difference\"])/len(test_frame[\"difference\"]),5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways:\n",
    "\n",
    "While we didn't achieve our goal of beating our BERT model (61% accuracy, 85% \"1-off\" accuracy), we managed to build a couple of models that get close.\n",
    "Our Count Vectorizer model, on the test set, achieves 47.23% accuracy with \"1-off\" accuracy of 64.9%. The final F1-score is 0.664.\n",
    "Our TfIdf Vectorizer model, on the test set, achieves 46.97% accuracy, with \"1-off\" accuracy of 63.63%. The final F1-score is 0.651\n",
    "Not too shabby!\n",
    "\n",
    "- All in all, our Spacy model performs slightly better than our Count/Tfidf vectorizer models. It achieves an accuracy of 52.74% on the testing set, with a \"1-off\" accuracy of 67.32%.\n",
    "\n",
    "|  Model         | Testing Accuracy  | 1-off Accuracy |\n",
    "| :---           |      :----:       |            ---:|\n",
    "| CountVectorize |   47.23%          |     64.9%      |\n",
    "| TfIdfVectorize |    46.97%         |     63.63%     |\n",
    "| Spacy (sm)     |     52.74%        |      67.32%    |\n",
    "| BERT           |     61%           |         85%    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
